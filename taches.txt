- remplir les vides rapport
    + cahier des charges : union entre 1.4 et 1.5
- tester le nv validateur
- structure des erreurs
- modifier la pipeline
    + systeme de classification

- s'interesser a l'aproche manuel aussi
    + reunir de hypotheses (commencer par des cas generales puis aller vers des trucs specifiques puis re generaliser : tel operateur avec tel configuration -> peu de chance que ca marche ou ca marchera jamais) puis on confirme j'hypothese
    + les isoler 
    + les analser
    + confirmer que le systeme ne marche pas avec ceux la

    + prendre les csv, en extrare les shemas qui marche pas
    + les prendre un par un et lancer pour voir les erreurs qu'ils retournent
    + le regrouper par classe en fonction des erreurs en commun


- retro ingenierie
    + pour chaque type de donnes; chaque operateur logique checker ce qu'il fait
    + regarder pour chque type de donnes quest ce qu'il fait
    

- datasets
    +containment: prob d'enumeration
    + truc un peu plus classiqe : github : chaque $ est une erreur : probleme de repitition et contexte
    + se concentrer sur un type d'erreur au debut pour voir
    + regenerer les output a 0 et se limiter au premier nvx d'erreur (prend le premier faux du everything)
    + avoir des outputs en json (annotation t'as compris)
    + si'il y en a bcp : prendre un echantillon

    + pas de containment
    + pas de handwritten

    + se comcentrer sur snowplow : potentiel problemem de type (il le choisis mal et max properties: il depasse)

-deroulement general
    1+ rendre dataset snowplow (3 shemas, 3 erreurs, pas aller dans le complique)
    2+ generer output
    3+ voir ou est le prob
    4+ aller dans le code
    5+ voir ou est le potentiel probleme

voici shema , voici instance, voici outpu de l'erreur, l'expliquer, la trouver dans le code (la partie responsable ex: aller dans le code chercher max properties)